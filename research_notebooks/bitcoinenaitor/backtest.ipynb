{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38ef2a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 05:21:49,717 - asyncio - ERROR - Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fadabff9580>\n",
      "2025-05-15 05:21:58,083 - asyncio - ERROR - Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-7' coro=<safe_wrapper() running at /home/dominhnhat/miniconda3/envs/quants-lab/lib/python3.12/site-packages/hummingbot/core/utils/async_utils.py:9> wait_for=<Future pending cb=[Task.task_wakeup()]>>\n"
     ]
    }
   ],
   "source": [
    "# This is necessary to recognize the modules\n",
    "import os\n",
    "import sys\n",
    "from decimal import Decimal\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from core.data_sources.clob import CLOBDataSource\n",
    "\n",
    "# Get trading rules and candles\n",
    "clob = CLOBDataSource()\n",
    "\n",
    "# Constants\n",
    "CONNECTOR_NAME = \"binance\"\n",
    "INTERVAL = \"1s\"\n",
    "TRADING_PAIR = \"BTC-USDT\"\n",
    "DAYS = 2\n",
    "\n",
    "await clob.get_candles_last_days(CONNECTOR_NAME, TRADING_PAIR, INTERVAL, DAYS)\n",
    "clob.dump_candles_cache(root_path)\n",
    "candles = clob.candles_cache[(\"binance\", \"BTC-USDT\", \"1s\")]\n",
    "df = candles.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db17fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def triple_barrier_method(df, tp=1.0, sl=1.0, tl=5, std_span: Optional[int] = 100, trade_cost=0.0006,  max_executors: int = 1):\n",
    "    df.index = pd.to_datetime(df.timestamp, unit=\"s\")\n",
    "    if std_span:\n",
    "        df[\"target\"] = df[\"close\"].rolling(std_span).std() / df[\"close\"]\n",
    "    else:\n",
    "        df[\"target\"] = 1 / 100\n",
    "    df[\"tl\"] = df.index + pd.Timedelta(seconds=tl)\n",
    "    df.dropna(subset=\"target\", inplace=True)\n",
    "\n",
    "    df = apply_tp_sl_on_tl(df, tp=tp, sl=sl)\n",
    "\n",
    "    df = get_bins(df, trade_cost)\n",
    "\n",
    "    df['tp'] = df['close'] * (1 + df['target'] * tp * df[\"side\"])\n",
    "    df['sl'] = df['close'] * (1 - df['target'] * sl * df[\"side\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_bins(df, trade_cost):\n",
    "    # 1) prices aligned with events\n",
    "    px = df.index.union(df['tl'].values).drop_duplicates()\n",
    "    px = df.close.reindex(px, method='ffill')\n",
    "\n",
    "    # 2) create out object\n",
    "    df['ret'] = (px.loc[df['close_time'].values].values / px.loc[df.index] - 1) * df['side']\n",
    "    df['real_class'] = np.sign(df['ret'] - trade_cost)\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_tp_sl_on_tl(df: pd.DataFrame, tp: float, sl: float):\n",
    "    events = df[df[\"side\"] != 0].copy()\n",
    "    if tp > 0:\n",
    "        take_profit = tp * events['target']\n",
    "    else:\n",
    "        take_profit = pd.Series(index=df.index)  # NaNs\n",
    "    if sl > 0:\n",
    "        stop_loss = - sl * events['target']\n",
    "    else:\n",
    "        stop_loss = pd.Series(index=df.index)  # NaNs\n",
    "\n",
    "    for loc, tl in events['tl'].fillna(df.index[-1]).items():\n",
    "        df0 = df.close[loc:tl]  # path prices\n",
    "        df0 = (df0 / df.close[loc] - 1) * events.at[loc, 'side']  # path returns\n",
    "        df.loc[loc, 'stop_loss_time'] = df0[df0 < stop_loss[loc]].index.min()  # earliest stop loss.\n",
    "        df.loc[loc, 'take_profit_time'] = df0[df0 > take_profit[loc]].index.min()  # earliest profit taking.\n",
    "    df[\"close_time\"] = df[[\"tl\", \"take_profit_time\", \"stop_loss_time\"]].dropna(how='all').min(axis=1)\n",
    "    df['close_type'] = df[['take_profit_time', 'stop_loss_time', 'tl']].dropna(how='all').idxmin(axis=1)\n",
    "    df['close_type'].replace({'take_profit_time': 1, 'stop_loss_time': -1, 'tl': 0}, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "135a3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Add technical indicators using pandas_ta\n",
    "import pandas_ta as ta\n",
    "\n",
    "df_copy = df.copy()\n",
    "df_copy[\"side\"] = 1\n",
    "df_with_tbm = triple_barrier_method(df_copy, tp=3.5, sl=3.5, tl=300, std_span=200, trade_cost=0.0000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1c224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "torch.Size([163368, 36])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "def process_data(df, loaded_scaler):\n",
    "    # Create a copy to work with\n",
    "    df_with_indicators = df.copy()\n",
    "\n",
    "    # Bollinger Bands with different lengths\n",
    "    df_with_indicators.ta.bbands(length=20, std=2, append=True)  # Standard BB\n",
    "    df_with_indicators.ta.bbands(length=50, std=2, append=True)  # Longer term BB\n",
    "\n",
    "    # MACD with different parameters\n",
    "    df_with_indicators.ta.macd(fast=12, slow=26, signal=9, append=True)  # Standard MACD\n",
    "    df_with_indicators.ta.macd(fast=8, slow=21, signal=5, append=True)  # Faster MACD\n",
    "\n",
    "    # RSI with different lengths\n",
    "    df_with_indicators.ta.rsi(length=14, append=True)  # Standard RSI\n",
    "    df_with_indicators.ta.rsi(length=21, append=True)  # Longer RSI\n",
    "\n",
    "    # Moving averages\n",
    "    df_with_indicators.ta.sma(length=20, append=True)  # Short MA\n",
    "    df_with_indicators.ta.sma(length=50, append=True)  # Medium MA\n",
    "    df_with_indicators.ta.ema(length=20, append=True)  # Short EMA\n",
    "    df_with_indicators.ta.ema(length=50, append=True)  # Medium EMA\n",
    "\n",
    "    # Volatility and momentum indicators\n",
    "    df_with_indicators.ta.atr(length=14, append=True)  # ATR\n",
    "    df_with_indicators.ta.stoch(k=14, d=3, append=True)  # Stochastic\n",
    "    df_with_indicators.ta.adx(length=14, append=True)  # ADX\n",
    "\n",
    "    # Replace df_with_tbm with df_with_indicators for further processing\n",
    "    df_processed = df_with_indicators.copy()\n",
    "    df_processed[\"close\"] = df[\"close\"]\n",
    "    # df_processed.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # 1. Remove unnecessary columns\n",
    "    columns_to_drop = ['timestamp', 'taker_buy_base_volume', 'volume', \n",
    "                    'close_time', 'real_class', 'ret', 'tp', 'sl', 'take_profit_time', 'stop_loss_time', 'tl', 'side']\n",
    "    df_processed = df_processed.drop(columns=columns_to_drop)\n",
    "    # 2. Convert prices to returns\n",
    "    price_columns = ['open', 'high', 'low', 'close']\n",
    "    for col in price_columns:\n",
    "        df_processed[f'{col}_ret'] = df_processed[col].pct_change()\n",
    "    # df_processed = df_processed.drop(columns=price_columns)\n",
    "\n",
    "    # 3. Create buy/sell volume ratio\n",
    "    df_processed['buy_volume_ratio'] = df_processed['taker_buy_quote_volume'] / df_processed['quote_asset_volume']\n",
    "    df_processed = df_processed.drop(columns=['taker_buy_quote_volume'])\n",
    "\n",
    "    # 4. Drop any rows with NaN values (first row will have NaN due to returns calculation)\n",
    "    df_processed = df_processed.dropna()\n",
    "\n",
    "    # 5. Get all numeric columns for scaling (excluding the target 'close_type')\n",
    "    numeric_columns = df_processed.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    numeric_columns.remove('close_type')  # Don't scale the target variable\n",
    "\n",
    "    # 6. Apply StandardScaler to all numeric columns\n",
    "    scaler = loaded_scaler\n",
    "    df_processed[numeric_columns] = scaler.fit_transform(df_processed[numeric_columns])\n",
    "    return df_processed\n",
    "\n",
    "def test(df, model, scaler, tp=1.0, sl=1.0, tl=5, std_span: Optional[int] = 100, trade_cost=0.0000):\n",
    "    \"\"\"\n",
    "    Test mô hình giao dịch với RandomForest.\n",
    "    Args:\n",
    "        df: DataFrame chứa dữ liệu đã được gán nhãn với Triple Barrier.\n",
    "        model: Mô hình sklearn (RandomForest) đã train.\n",
    "        scaler: StandardScaler dùng lúc training.\n",
    "        tp, sl, tl: các tham số của Triple Barrier.\n",
    "        std_span: khoảng thời gian tính std.\n",
    "        trade_cost: chi phí giao dịch.\n",
    "    Returns:\n",
    "        pnl: Tổng lợi nhuận.\n",
    "        num_trade: Tổng số lệnh giao dịch.\n",
    "        accuracy: Độ chính xác của mô hình.\n",
    "    \"\"\"\n",
    "    df_test = df.copy()\n",
    "    df_test = process_data(df_test, scaler)\n",
    "    feature_columns = [col for col in df_test.columns if col not in ['open', 'high', 'low', 'close','timestamp', 'tl', 'stop_loss_time', \n",
    "                                                                'take_profit_time', 'close_time', 'close_type',\n",
    "                                                                'real_class', 'ret', 'target_pct']]\n",
    "    print(len(feature_columns))\n",
    "\n",
    "    X_test = df_test[feature_columns]\n",
    "    Y_test = df_test['close_type']\n",
    "\n",
    "\n",
    "    # 3. Dự đoán tín hiệu entry: 1 = mua, -1 = bán, 0 = không giao dịch\n",
    "    X_test_tensor  = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    print(X_test_tensor.shape)\n",
    "    entry_signals = model(X_test_tensor).detach().numpy()\n",
    "\n",
    "\n",
    "    # Tính accuracy\n",
    "    #print(entry_signals)\n",
    "    #print(Y_test)\n",
    "    acc = 0\n",
    "    bitcoin = 0.0\n",
    "    pnl = Quota = 1000.0\n",
    "    num_trade = 0\n",
    "\n",
    "    for i in range(len(df_test)):\n",
    "        \n",
    "        entry_sig = entry_signals[i].argmax()\n",
    "        #print(entry_sig, entry_signals[i])\n",
    "        signal = entry_sig\n",
    "        close_price = df.iloc[i][\"close\"]\n",
    "\n",
    "        if (entry_sig == 0): \n",
    "            signal = -1\n",
    "        elif (entry_sig == 1): \n",
    "            signal = 0\n",
    "        else:\n",
    "            signal = 1\n",
    "\n",
    "        if (signal == Y_test[i]): acc += 1\n",
    "\n",
    "        print(\"pnl:\", pnl, \"bitcoin:\", bitcoin, \"close_price:\", close_price, \"signal:\", signal)\n",
    "        \n",
    "        \n",
    "\n",
    "        buy_amount = 0.0001\n",
    "\n",
    "        total_value = pnl + bitcoin * close_price\n",
    "        if pnl <= close_price* buy_amount and bitcoin == 0:\n",
    "            print(\"Suffered from liquidation lmao\", pnl, bitcoin)\n",
    "            break\n",
    "\n",
    "        if signal == 1:  # buy\n",
    "            cost = close_price * buy_amount + trade_cost\n",
    "            if pnl >= cost:\n",
    "                bitcoin += buy_amount\n",
    "                pnl -= cost\n",
    "                num_trade += 1\n",
    "\n",
    "        elif signal == -1 and bitcoin > 0:  # sell\n",
    "            proceeds = close_price * bitcoin - trade_cost\n",
    "            pnl += proceeds\n",
    "            bitcoin = 0.0\n",
    "            num_trade += 1\n",
    "\n",
    "    \n",
    "    return pnl - Quota, num_trade, acc/num_trade\n",
    "\n",
    "\n",
    "# Ví dụ về cách sử dụng:\n",
    "# Giả sử bạn đã có một mô hình học máy (model) với hàm entry\n",
    "\n",
    "df_test = df_with_tbm.copy()\n",
    "\n",
    "# Test mô hình với hàm test\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "scaler_path = '/home/dominhnhat/quants-lab/research_notebooks/bitcoinenaitor/models/scaler.pkl'\n",
    "model_path = '/home/dominhnhat/quants-lab/research_notebooks/bitcoinenaitor/models/mlp.pth'\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.drop3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.drop4 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc5 = nn.Linear(64, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.drop4(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = 36  # number of feature columns\n",
    "model = MLP(input_dim)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "pnl, num_trade, accuracy = test(df_test, model, scaler)\n",
    "\n",
    "print(f\"Total PNL: {pnl}, Number of Trades: {num_trade}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391bd318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quants-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
